{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para modificar el dataset para trabajar con efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class YOLODataset(Dataset):\n",
    "    def __init__(self, root_dir, mode=\"train\", transform=None):\n",
    "        self.image_dir = os.path.join(root_dir, \"images\", mode)\n",
    "        self.label_dir = os.path.join(root_dir, \"labels\", mode)\n",
    "        self.transform = transform\n",
    "        self.data = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        data = []\n",
    "        for label_file in os.listdir(self.label_dir):\n",
    "            label_path = os.path.join(self.label_dir, label_file)\n",
    "            with open(label_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                \n",
    "                # Verificar que haya al menos 2 filas\n",
    "                if len(lines) < 2:\n",
    "                    print(f\" Advertencia: {label_file} no tiene suficiente información\")\n",
    "                    continue  \n",
    "                \n",
    "                parts = lines[1].strip().split()  \n",
    "\n",
    "                try:\n",
    "                    class_label = int(parts[0]) - 1  \n",
    "                    image_path = os.path.join(self.image_dir, label_file.replace('.txt', '.jpg'))\n",
    "                    \n",
    "                    if os.path.exists(image_path):  \n",
    "                        data.append((image_path, class_label))\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error procesando {label_file}: {e}\")\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "root_dir = \"dataset_yolo\"\n",
    "\n",
    "train_dataset = YOLODataset(root_dir, mode=\"train\", transform=transform)\n",
    "valid_dataset = YOLODataset(root_dir, mode=\"valid\", transform=transform)\n",
    "test_dataset = YOLODataset(root_dir, mode=\"test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementacion de efficientnet para la clasificacion de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#  Cargar EfficientNet-B0 preentrenado\n",
    "model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, 2)  # 2 clases (binario)\n",
    "model = model.to(device)\n",
    "\n",
    "#  Definir función de pérdida y optimizador\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#  Cargar checkpoints si existen\n",
    "checkpoint_path = \"efficientnet_checkpoint.pth\"\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    if 'model_state' in checkpoint and 'optimizer_state' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "    else:\n",
    "        print(\"Checkpoint corrupto. Entrenando desde 0.\")\n",
    "        start_epoch = 0\n",
    "else:\n",
    "    start_epoch = 0\n",
    "\n",
    "#  Archivo CSV para guardar métricas\n",
    "metrics_file = \"efficientnet_metrics.csv\"\n",
    "if not os.path.exists(metrics_file):\n",
    "    with open(metrics_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"Epoca\", \"Perdida\", \"Precision (Entrenamiento)\", \"Precision (Validacion)\"])\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "\n",
    "    model.eval()\n",
    "    correct_valid = 0\n",
    "    total_valid = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_valid += (predicted == labels).sum().item()\n",
    "            total_valid += labels.size(0)\n",
    "\n",
    "    valid_accuracy = 100 * correct_valid / total_valid\n",
    "\n",
    "    print(f\"Época {epoch + 1}/{num_epochs}, Pérdida: {train_loss:.4f}, Precisión (Train): {train_accuracy:.2f}%, Precisión (Valid): {valid_accuracy:.2f}%\")\n",
    "\n",
    "    with open(metrics_file, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([epoch + 1, train_loss, train_accuracy, valid_accuracy])\n",
    "\n",
    "    #  Guardar checkpoint cada época\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state': model.state_dict(),\n",
    "        'optimizer_state': optimizer.state_dict(),\n",
    "    }, checkpoint_path)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
